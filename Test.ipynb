{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import scipy\n",
    "import json\n",
    "import torchvision.transforms.functional as F\n",
    "from matplotlib import cm as CM\n",
    "from image import *\n",
    "from model import CSRNet\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225]),\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"test/test_images/circles-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy = os.path.join(root,\"easy\")\n",
    "real = os.path.join(root,\"realistic\")\n",
    "challanging = os.path.join(root,\"challanging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for img_path in natsorted(glob.glob(os.path.join(easy, \"*.jpg\"))):\n",
    "    img_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CSRNet()\n",
    "model = model.cuda()\n",
    "checkpoint = torch.load('test/circles/38checkpoint.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 399 objects 22.211 objects were miss-counted. 6.487 were overcounted and 15.724 were undercounted\n",
      "Mean absolute error  2.468\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import cm as c\n",
    "folder = real\n",
    "n = 1\n",
    "mae = 0\n",
    "total = 0\n",
    "under = 0\n",
    "over = 0\n",
    "for i in img_paths:\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    image = Image.open(i).convert('RGB')\n",
    "    image = image.resize((1024, 768))\n",
    "    img = transform(image.convert('RGB')).cuda()\n",
    "    output = model(img.unsqueeze(0))\n",
    "    #print(\"Predicted Count : \",np.round(output.detach().cpu().sum().numpy(), 3))\n",
    "    predicted = np.round(output.detach().cpu().sum().numpy(), 3)\n",
    "    temp = np.asarray(output.detach().cpu().reshape(output.detach().cpu().shape[2],output.detach().cpu().shape[3]))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(str(predicted))\n",
    "    plt.imshow(temp,cmap = c.jet)\n",
    "    \n",
    "    original_count = int((i.split('/')[-1]).split('.')[0])\n",
    "    total += original_count\n",
    "    \n",
    "    error = predicted - original_count\n",
    "    if error > 0:\n",
    "        over += error\n",
    "    elif error <0:\n",
    "        under += abs(error)\n",
    "    mae += abs(error)\n",
    "    \n",
    "    \n",
    "    original_image = plt.imread(i)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Original Count ' + str(original_count))\n",
    "    plt.imshow(original_image)\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.savefig(folder+'test'+str(n)+'.jpg', bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    n = n+1\n",
    "    \n",
    "\n",
    "print(\"Out of {} objects {} objects were miss-counted. {} were overcounted and {} were undercounted\"\n",
    "              .format(np.round(total, 3), np.round(mae, 3), np.round(over,3), np.round(under,3)))\n",
    "print(\"Mean absolute error \", np.round(mae/9, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
